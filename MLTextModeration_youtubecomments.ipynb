{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1iODr/KVLZ9mYx7ou/2+o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prasadanvekar/elvtrdocs/blob/main/MLTextModeration_youtubecomments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h64J6BNpIw8h"
      },
      "outputs": [],
      "source": [
        "#Objective: To implement Text Moderation using Juypter Notebook\n",
        "\n",
        "#First step: For this implementation, we will be using Youtube toxic comment dataset from Kaggle.\n",
        "# https://www.kaggle.com/datasets/reihanenamdari/youtube-toxicity-data?resource=download\n",
        "\n",
        "# Second Step: To upload the data to Google Colab environment as a pre-requisite.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load Data\n",
        "DATA_PATH = \"youtoxic_english_1000.csv\"\n",
        "\n",
        "if os.path.exists(DATA_PATH):\n",
        "    # Read from file if we've already downloaded the data.\n",
        "    with open(DATA_PATH) as f:\n",
        "        df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# Display first few rows to validate the data\n",
        "print(df.head(5))\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Check for duplicate rows\n",
        "print(df.duplicated().sum())\n",
        "\n",
        "# Drop duplicate rows\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Check for class imbalance\n",
        "print(df['IsToxic'].value_counts())\n",
        "\n",
        "# Print the column names to verify 'text' exists\n",
        "print(df.columns)  # Check if 'text' is present and correctly named\n",
        "\n",
        "# prompt: Using dataframe df: IsToxic\n",
        "df['IsToxic'].value_counts() # Count the number of True and False values in the IsToxic column\n",
        "\n",
        "\n",
        "# Download NLTK resources\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Preprocess text\n",
        "def preprocess_text(Text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(Text)\n",
        "    # Remove punctuation and lowercase\n",
        "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if not word in stop_words]\n",
        "    # Join tokens back into text\n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply preprocessing\n",
        "df['processed_text'] = df['Text'].apply(preprocess_text)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_text'], df['IsToxic'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize text using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # adjust max_features as needed\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Train a logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "WRynJGcRT_x1",
        "outputId": "d0c77f1d-9859-419e-ef65-a2038cb60aef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              CommentId      VideoId  \\\n",
            "0  Ugg2KwwX0V8-aXgCoAEC  04kJtp6pVXI   \n",
            "1  Ugg2s5AzSPioEXgCoAEC  04kJtp6pVXI   \n",
            "2  Ugg3dWTOxryFfHgCoAEC  04kJtp6pVXI   \n",
            "3  Ugg7Gd006w1MPngCoAEC  04kJtp6pVXI   \n",
            "4  Ugg8FfTbbNF8IngCoAEC  04kJtp6pVXI   \n",
            "\n",
            "                                                Text  IsToxic  IsAbusive  \\\n",
            "0  If only people would just take a step back and...    False      False   \n",
            "1  Law enforcement is not trained to shoot to app...     True       True   \n",
            "2  \\nDont you reckon them 'black lives matter' ba...     True       True   \n",
            "3  There are a very large number of people who do...    False      False   \n",
            "4  The Arab dude is absolutely right, he should h...    False      False   \n",
            "\n",
            "   IsThreat  IsProvocative  IsObscene  IsHatespeech  IsRacist  IsNationalist  \\\n",
            "0     False          False      False         False     False          False   \n",
            "1     False          False      False         False     False          False   \n",
            "2     False          False       True         False     False          False   \n",
            "3     False          False      False         False     False          False   \n",
            "4     False          False      False         False     False          False   \n",
            "\n",
            "   IsSexist  IsHomophobic  IsReligiousHate  IsRadicalism  \n",
            "0     False         False            False         False  \n",
            "1     False         False            False         False  \n",
            "2     False         False            False         False  \n",
            "3     False         False            False         False  \n",
            "4     False         False            False         False  \n",
            "CommentId          0\n",
            "VideoId            0\n",
            "Text               0\n",
            "IsToxic            0\n",
            "IsAbusive          0\n",
            "IsThreat           0\n",
            "IsProvocative      0\n",
            "IsObscene          0\n",
            "IsHatespeech       0\n",
            "IsRacist           0\n",
            "IsNationalist      0\n",
            "IsSexist           0\n",
            "IsHomophobic       0\n",
            "IsReligiousHate    0\n",
            "IsRadicalism       0\n",
            "dtype: int64\n",
            "0\n",
            "IsToxic\n",
            "False    538\n",
            "True     462\n",
            "Name: count, dtype: int64\n",
            "Index(['CommentId', 'VideoId', 'Text', 'IsToxic', 'IsAbusive', 'IsThreat',\n",
            "       'IsProvocative', 'IsObscene', 'IsHatespeech', 'IsRacist',\n",
            "       'IsNationalist', 'IsSexist', 'IsHomophobic', 'IsReligiousHate',\n",
            "       'IsRadicalism'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.66\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.60      0.81      0.69        93\n",
            "        True       0.76      0.53      0.63       107\n",
            "\n",
            "    accuracy                           0.66       200\n",
            "   macro avg       0.68      0.67      0.66       200\n",
            "weighted avg       0.69      0.66      0.66       200\n",
            "\n"
          ]
        }
      ]
    }
  ]
}