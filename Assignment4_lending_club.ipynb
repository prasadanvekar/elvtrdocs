{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP09BR7HLWLAwxIq62TNs3V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prasadanvekar/elvtrdocs/blob/main/Assignment4_lending_club.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################################\n",
        "# Assignment#4: Lending Club.                                                                 #\n",
        "# Objective : apply essential data cleaning and transformation techniques to prepare the data #\n",
        "# for further analysis and modeling.                                                          #\n",
        "# Author: Prasad S Anvekar                                                                    #\n",
        "# Date: 28 Dec 2023                                                                           #\n",
        "###############################################################################################\n",
        "\n",
        "# Importing the required libraries\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define the Data Path where the file are located.\n",
        "\n",
        "DATA_PATH = \"accepted_2007_to_2018Q4.csv\"\n",
        "\n",
        "# Error Hanlding for Data Path and File not found scenarios.\n",
        "\n",
        "if os.path.exists(DATA_PATH):\n",
        "    # Read from file if we've already downloaded the data.\n",
        "    with open(DATA_PATH) as f:\n",
        "        data = pd.read_csv('accepted_2007_to_2018Q4.csv', low_memory=False)\n",
        "else:\n",
        "     print(\"File not found!\")\n",
        "\n",
        "# Data exploration & Preprocessing\n",
        "# understanding the data\n",
        "\n",
        "# Get the number of columns\n",
        "num_columns = data.shape[1]\n",
        "\n",
        "# Display column names\n",
        "column_names = data.columns.tolist()\n",
        "\n",
        "print(f\"Number of Columns: {num_columns}\")\n",
        "print(f\"Column Names: {column_names}\")\n",
        "\n",
        "# Original Data:\n",
        "# To view the first 5 rows of the datasets\n",
        "print('Original Data - Display first few(5) rows of dataset:')\n",
        "print(data.head())\n",
        "\n",
        "# importing selected columns for this assignments\n",
        "# Specify the columns you want to import\n",
        "numeric_columns = ['id','loan_amnt', 'int_rate', 'annual_inc','settlement_amount','settlement_term','settlement_percentage']\n",
        "character_columns = ['term', 'grade', 'emp_length','verification_status','loan_status','settlement_status','disbursement_method', 'debt_settlement_flag']\n",
        "\n",
        "# Read the CSV file with selected columns\n",
        "selected_columns = numeric_columns + character_columns\n",
        "df = pd.read_csv(DATA_PATH, usecols=selected_columns)\n",
        "\n",
        "# Create a heatmap to visualize the correlation between numeric values')\n",
        "correlation_matrix = df.corr()\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(correlation_matrix,annot=True,cmap='coolwarm',fmt='.2f')\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "# Create a box plot to visualize the distribution of income\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.boxplot(y='annual_inc',data=data)\n",
        "plt.title('Box Plot of Income')\n",
        "plt.ylabel('Income')\n",
        "plt.show()\n",
        "\n",
        "# To view the first 5 rows of the datasets\n",
        "print('Inspect Data - Display first few(5) rows of dataset:')\n",
        "print(df.head())\n",
        "\n",
        "# To view the last 5 rows of the datasets\n",
        "print('Inspect Data - Display last few(5) rows of dataset:')\n",
        "print(df.tail())\n",
        "\n",
        "# Check for any missing values\n",
        "print('Inspect any missing values:')\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# To view the column details of the datasets. To choose the right target variable.\n",
        "print('Inspect Data - Describe the column in the dataset:')\n",
        "print(df.describe())\n",
        "\n",
        "# to check the data types\n",
        "print('Inspect Data - check data types:')\n",
        "print(df.dtypes)\n",
        "\n",
        "# Handling the Missing Values:\n",
        "# for this assignment will be choosing 3 numeric - loan_amnt,int_rate,settlement_amount\n",
        "# and 3 character fields - settlement_status,debt_settlement_flag,disbursement_method\n",
        "# Replacing missing values with a mean (loan_amt, int_rate)\n",
        "imputer = SimpleImputer(missing_values=np.nan,strategy='mean')\n",
        "df[['loan_amnt', 'int_rate']] = imputer.fit_transform(df[['loan_amnt', 'int_rate']])\n",
        "\n",
        "# Replacing missing values with a constant\n",
        "imputer_1 = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
        "df[['settlement_amount','settlement_term','settlement_percentage']] = imputer_1.fit_transform(df[['settlement_amount','settlement_term','settlement_percentage']])\n",
        "\n",
        "# Replacing missing values with a constant\n",
        "imputer_2 = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='N')\n",
        "df[['settlement_status','debt_settlement_flag']] = imputer_2.fit_transform(df[['settlement_status','debt_settlement_flag']])\n",
        "\n",
        "# Replacing missing values with a constant\n",
        "#imputer_3 = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=None)\n",
        "#data[['disbursement_method']] = imputer_3.fit_transform(data[['disbursement_method']])\n",
        "\n",
        "print(\"Missing data replaced with constant & mean\")\n",
        "print(df.head())\n",
        "\n",
        "# Check for any missing values\n",
        "print('Inspect any missing values post data imputation:')\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# dropping the rows with null values\n",
        "df.dropna(subset=[''], inplace=True)\n",
        "\n",
        "# Encoding categorical variables (grade, loan_status)\n",
        "le = LabelEncoder()\n",
        "df['grade'] = le.fit_transform(df['grade'])\n",
        "df['loan_status'] = le.fit_transform(df['loan_status'])\n",
        "\n",
        "print(\"one-hot Encoding categorical data: \")\n",
        "print(df)\n",
        "\n",
        "# Scaling numerical features (Annual Income) using StandardScaler:\n",
        "scaler = StandardScaler()\n",
        "df[['annual_inc']] = scaler.fit_transform(df[['annual_inc']])\n",
        "\n",
        "#Display the preprocessed and cleansed data\n",
        "print(\"Scaling numnerical features using StandardScaler: \")\n",
        "print(df)\n",
        "\n",
        "# write the transformed data to a new csv file for further processing & analysis.\n",
        "#df.to_csv('accepted_2007_to_2018Q4_modified.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "B-Nx8M02HunX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        },
        "outputId": "5d617dbc-deeb-4808-9fb8-c2994bc39889"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Columns: 151\n",
            "Column Names: ['id', 'member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'annual_inc', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'url', 'desc', 'purpose', 'title', 'zip_code', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line', 'fico_range_low', 'fico_range_high', 'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'initial_list_status', 'out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d', 'last_fico_range_high', 'last_fico_range_low', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'policy_code', 'application_type', 'annual_inc_joint', 'dti_joint', 'verification_status_joint', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_act_il', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m', 'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_bc_dlq', 'mths_since_recent_inq', 'mths_since_recent_revol_delinq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies', 'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit', 'revol_bal_joint', 'sec_app_fico_range_low', 'sec_app_fico_range_high', 'sec_app_earliest_cr_line', 'sec_app_inq_last_6mths', 'sec_app_mort_acc', 'sec_app_open_acc', 'sec_app_revol_util', 'sec_app_open_act_il', 'sec_app_num_rev_accts', 'sec_app_chargeoff_within_12_mths', 'sec_app_collections_12_mths_ex_med', 'sec_app_mths_since_last_major_derog', 'hardship_flag', 'hardship_type', 'hardship_reason', 'hardship_status', 'deferral_term', 'hardship_amount', 'hardship_start_date', 'hardship_end_date', 'payment_plan_start_date', 'hardship_length', 'hardship_dpd', 'hardship_loan_status', 'orig_projected_additional_accrued_interest', 'hardship_payoff_balance_amount', 'hardship_last_payment_amount', 'disbursement_method', 'debt_settlement_flag', 'debt_settlement_flag_date', 'settlement_status', 'settlement_date', 'settlement_amount', 'settlement_percentage', 'settlement_term']\n",
            "Original Data - Display first few(5) rows of dataset:\n",
            "         id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
            "0  68407277        NaN     3600.0       3600.0           3600.0   36 months   \n",
            "1  68355089        NaN    24700.0      24700.0          24700.0   36 months   \n",
            "2  68341763        NaN    20000.0      20000.0          20000.0   60 months   \n",
            "3  66310712        NaN    35000.0      35000.0          35000.0   60 months   \n",
            "4  68476807        NaN    10400.0      10400.0          10400.0   60 months   \n",
            "\n",
            "   int_rate  installment grade sub_grade  ... hardship_payoff_balance_amount  \\\n",
            "0     13.99       123.03     C        C4  ...                            NaN   \n",
            "1     11.99       820.28     C        C1  ...                            NaN   \n",
            "2     10.78       432.66     B        B4  ...                            NaN   \n",
            "3     14.85       829.90     C        C5  ...                            NaN   \n",
            "4     22.45       289.91     F        F1  ...                            NaN   \n",
            "\n",
            "  hardship_last_payment_amount disbursement_method  debt_settlement_flag  \\\n",
            "0                          NaN                Cash                     N   \n",
            "1                          NaN                Cash                     N   \n",
            "2                          NaN                Cash                     N   \n",
            "3                          NaN                Cash                     N   \n",
            "4                          NaN                Cash                     N   \n",
            "\n",
            "  debt_settlement_flag_date settlement_status settlement_date  \\\n",
            "0                       NaN               NaN             NaN   \n",
            "1                       NaN               NaN             NaN   \n",
            "2                       NaN               NaN             NaN   \n",
            "3                       NaN               NaN             NaN   \n",
            "4                       NaN               NaN             NaN   \n",
            "\n",
            "  settlement_amount settlement_percentage settlement_term  \n",
            "0               NaN                   NaN             NaN  \n",
            "1               NaN                   NaN             NaN  \n",
            "2               NaN                   NaN             NaN  \n",
            "3               NaN                   NaN             NaN  \n",
            "4               NaN                   NaN             NaN  \n",
            "\n",
            "[5 rows x 151 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cf456c9e360e>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Create a heatmap to visualize the correlation between numeric values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mcorrelation_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'loan_amnt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int_rate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'annual_inc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'settlement_amount'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'settlement_term'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'settlement_percentage'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrelation_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coolwarm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.2f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: DataFrame.corr() takes from 1 to 4 positional arguments but 8 were given"
          ]
        }
      ]
    }
  ]
}