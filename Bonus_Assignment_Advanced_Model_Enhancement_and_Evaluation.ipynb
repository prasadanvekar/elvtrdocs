{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+r4peFsVbLn97drqK83UX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prasadanvekar/elvtrdocs/blob/main/Bonus_Assignment_Advanced_Model_Enhancement_and_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PDycod9-TQZ"
      },
      "outputs": [],
      "source": [
        "##############################################################################\n",
        "# Objective: applying more sophisticated techniques in model enhancement     #\n",
        "# and evaluation within the context of fraud detection                       #\n",
        "# Date: 13 Jan 2024                                                          #\n",
        "# Author: Prasad S Anvekar                                                   #\n",
        "##############################################################################\n",
        "#Data upload\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,  roc_curve, auc\n",
        "from sklearn.tree import plot_tree\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://raw.githubusercontent.com/marhcouto/fraud-detection/master/data/card_transdata.csv?raw=true'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "#######################################\n",
        "#Data exploration section             #\n",
        "#######################################\n",
        "\n",
        "# Print the top and bottom 5 rows\n",
        "print(data.head(5))\n",
        "print(\"\")\n",
        "\n",
        "# Section 2: Data Exploration\n",
        "# Summary statistics\n",
        "print(data.describe())\n",
        "\n",
        "# Event rate\n",
        "event_rate = data['fraud'].mean() * 100\n",
        "print(f'Event Rate: {event_rate:.2f}%')\n",
        "\n",
        "# Check for missing values in the dataset\n",
        "missing_values = data.isnull().sum()\n",
        "missing_percentage = (data.isnull().sum() / len(data)) * 100\n",
        "\n",
        "# Analysis specific to the target variable 'default'\n",
        "missing_values_target = missing_values['fraud']\n",
        "missing_percentage_target = missing_percentage['fraud']\n",
        "\n",
        "# Preparing the analysis output for the entire dataset and for the target variable\n",
        "missing_data_analysis = pd.DataFrame({\n",
        "    'Feature': data.columns,\n",
        "    'Missing Values': missing_values,\n",
        "    'Percentage (%)': missing_percentage\n",
        "})\n",
        "\n",
        "missing_data_analysis_target = pd.DataFrame({\n",
        "    'Feature': ['fraud'],\n",
        "    'Missing Values': [missing_values_target],\n",
        "    'Percentage (%)': [missing_percentage_target]\n",
        "})\n",
        "\n",
        "# To display the analysis results\n",
        "print(\"Missing Data Analysis for the Entire Dataset:\")\n",
        "print(missing_data_analysis)\n",
        "print(\"\\nMissing Data Analysis for the Target Variable 'default':\")\n",
        "print(missing_data_analysis_target)\n",
        "\n",
        "\n",
        "# Heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
        "plt.title('Heatmap of Correlation Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Box plot visualization\n",
        "print(\"\\n--- Box Plots for Each Numeric Column ---\")\n",
        "numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "n_rows, n_cols = 3, 3\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    sns.boxplot(x=data[col], ax=axes[i])\n",
        "    axes[i].set_title(f'Boxplot of {col}')\n",
        "for i in range(len(numeric_cols), len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the atrributes (X) and the label (y)\n",
        "X = data.drop('fraud', axis=1)\n",
        "y = data['fraud']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "################################################################################\n",
        "#Adjusting the outlier with 1.5 IQR                                            #\n",
        "################################################################################\n",
        "# Make copies of the original training and testing data for comparison\n",
        "original_train = X_train.copy()\n",
        "original_test = X_test.copy()\n",
        "\n",
        "# Adjust for outliers and create binary indicators for both train and test sets\n",
        "for feature in X_train.columns:\n",
        "    Q1 = X_train[feature].quantile(0.25)\n",
        "    Q3 = X_train[feature].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Create a new binary column indicating if the value was adjusted\n",
        "    outlier_col_name = f'{feature}_outlier'\n",
        "    X_train[outlier_col_name] = ((X_train[feature] < lower_bound) | (X_train[feature] > upper_bound)).astype(int)\n",
        "    X_test[outlier_col_name] = ((X_test[feature] < lower_bound) | (X_test[feature] > upper_bound)).astype(int)\n",
        "\n",
        "    # Adjust the feature values for outliers\n",
        "    X_train[feature] = np.clip(X_train[feature], lower_bound, upper_bound)\n",
        "    X_test[feature] = np.clip(X_test[feature], lower_bound, upper_bound)\n",
        "\n",
        "# Visualization of original vs adjusted distributions\n",
        "numeric_features = original_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "n_cols = 3\n",
        "n_rows = (len(numeric_features) + n_cols - 1) // n_cols\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 4))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, feature in enumerate(numeric_features):\n",
        "    sns.histplot(original_train[feature], color=\"skyblue\", kde=True, ax=axes[i], label='Original')\n",
        "    sns.histplot(X_train[feature], color=\"red\", kde=True, ax=axes[i], label='Adjusted', alpha=0.6)\n",
        "    axes[i].set_title(feature)\n",
        "    axes[i].legend()\n",
        "\n",
        "# Remove unused subplots\n",
        "for i in range(len(numeric_features), len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Feature Engineering Section                                                  #\n",
        "################################################################################\n",
        "# Original feature names without binary indicators\n",
        "original_features = ['distance_from_home', 'distance_from_last_transaction', 'ratio_to_median_purchase_price', 'repeat_retailer', 'used_chip', 'used_pin_number', 'online_order']\n",
        "\n",
        "# Create PolynomialFeatures instance with interaction_only=False to include squared terms\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
        "\n",
        "# Fit and transform the training data with original features, interaction terms, and squared terms\n",
        "X_train_poly = poly.fit_transform(X_train[original_features])\n",
        "X_test_poly = poly.transform(X_test[original_features])\n",
        "\n",
        "# Get the feature names after polynomial transformation\n",
        "poly_feature_names = poly.get_feature_names_out(original_features)\n",
        "\n",
        "print(\"Filtered Polynomial and Interaction Features:\", poly_feature_names)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_poly)\n",
        "X_test_scaled = scaler.transform(X_test_poly)\n",
        "\n",
        "# Create DataFrames for the scaled data\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=poly_feature_names)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=poly_feature_names)\n",
        "\n",
        "# Visualization for Comparison\n",
        "#n_cols = 2  # Columns for original and scaled data\n",
        "#n_rows = len(original_features)  # Number of rows is based on the number of original features\n",
        "\n",
        "#fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, n_rows * 2))\n",
        "#axes = axes.flatten()\n",
        "\n",
        "#for i, feature in enumerate(original_features):\n",
        "    # Original feature distribution\n",
        "#    sns.histplot(X_train_scaled[:, feature], kde=True, ax=axes[2*i], color=\"skyblue\", label='Original')\n",
        "#    axes[2*i].set_title(f'Original Distribution of {feature}')\n",
        "\n",
        "    # Scaled feature distribution\n",
        "#    sns.histplot(X_train_scaled_df[feature], kde=True, ax=axes[2*i + 1], color=\"salmon\", label='Scaled', alpha=0.6)\n",
        "#    axes[2*i + 1].set_title(f'Scaled Distribution of {feature}')\n",
        "\n",
        "#plt.tight_layout()\n",
        "#plt.show()\n",
        "\n",
        "# Visualization of box plots for outlier-adjusted and scaled features\n",
        "#original_features = ['distance_from_home', 'distance_from_last_transaction', 'ratio_to_median_purchase_price', 'repeat_retailer', 'used_chip', 'used_pin_number', 'online_order']\n",
        "#n_cols = 2  # Two columns for each feature: outlier-adjusted and scaled\n",
        "#n_rows = len(original_features)\n",
        "\n",
        "#fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, n_rows * 2))\n",
        "#axes = axes.flatten()\n",
        "\n",
        "#for i, feature in enumerate(original_features):\n",
        "    # Outlier-adjusted feature boxplot\n",
        "#    sns.boxplot(x=X_train_scaled[feature], ax=axes[2*i])\n",
        "#    axes[2*i].set_title(f'Outlier-Adjusted {feature}')\n",
        "\n",
        "    # Scaled feature boxplot\n",
        "#    scaled_feature_name = feature  # Update if the scaled feature name is different\n",
        "#    sns.boxplot(x=X_train_scaled_df[scaled_feature_name], ax=axes[2*i + 1])\n",
        "#    axes[2*i + 1].set_title(f'Scaled {scaled_feature_name}')\n",
        "\n",
        "#plt.tight_layout()\n",
        "#plt.show()\n",
        "\n",
        "################################################################################\n",
        "\n",
        "####################################################################\n",
        "# Decision Tree Model                                              #\n",
        "####################################################################\n",
        "# Define the hyperparameters for the Decision Tree\n",
        "dt_params = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Create GridSearchCV object with DecisionTreeClassifier\n",
        "dt = GridSearchCV(DecisionTreeClassifier(), dt_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit the model on the training set using the scaled features\n",
        "dt.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "dt_pred = dt.predict(X_test_scaled)\n",
        "\n",
        "# Calculate the performance metrics\n",
        "tree_acc = accuracy_score(y_test, dt_pred)  # Changed variable name to 'tree_acc'\n",
        "tree_recall = recall_score(y_test, dt_pred)  # Changed variable name to 'tree_recall'\n",
        "tree_precision = precision_score(y_test, dt_pred)  # Changed variable name to 'tree_precision'\n",
        "\n",
        "# Decision Tree Visualization\n",
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'poly' is the PolynomialFeatures instance used for transformation\n",
        "# and 'dt' is the trained DecisionTreeClassifier within GridSearchCV\n",
        "feature_names_poly = poly.get_feature_names_out().tolist()  # Convert to list\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "# Using the feature names from PolynomialFeatures for visualization\n",
        "plot_tree(dt.best_estimator_, filled=True, feature_names=feature_names_poly, class_names=['No Default', 'Default'])\n",
        "plt.title(\"Decision Tree Visualization\")\n",
        "plt.show()\n",
        "\n",
        "# Print the performance metrics\n",
        "print(f\"Decision Tree - Accuracy: {tree_acc:.3f}\")\n",
        "print(f\"Decision Tree - Recall: {tree_recall:.3f}\")\n",
        "print(f\"Decision Tree - Precision: {tree_precision:.3f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, dt_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
        "plt.title('Decision Tree Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "y_pred_prob = dt.best_estimator_.predict_proba(X_test_scaled)[:, 1]\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.plot(fpr, tpr, label='ROC Curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Decision Tree ROC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Decision Boundary Analysis\n",
        "# Reduce dimensions for visualization\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "\n",
        "# Train Decision Tree on the first two principal components for visualization\n",
        "dt_pca = DecisionTreeClassifier(max_depth=dt.best_params_['max_depth'])\n",
        "dt_pca.fit(X_train_pca, y_train)\n",
        "\n",
        "# Create a mesh grid on the PCA-reduced 2D space\n",
        "x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
        "y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                     np.linspace(y_min, y_max, 100))\n",
        "\n",
        "# Predict on the mesh grid\n",
        "Z = dt_pca.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot decision boundary\n",
        "plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, edgecolors='k')\n",
        "plt.xlabel('PCA1')\n",
        "plt.ylabel('PCA2')\n",
        "plt.title('Decision Tree Decision Boundary with PCA-reduced Features')\n",
        "plt.show()\n",
        "\n",
        "####################################################################\n",
        "# Random Forest Model                                              #\n",
        "####################################################################\n",
        "\n",
        "# Define the hyperparameters for the Random Forest\n",
        "rf_params = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2']  # 'auto' is equivalent to 'sqrt'\n",
        "}\n",
        "\n",
        "# Create GridSearchCV object with RandomForestClassifier\n",
        "rf = GridSearchCV(RandomForestClassifier(), rf_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit the model on the training set using the scaled features\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "rf_pred = rf.predict(X_test_scaled)\n",
        "\n",
        "# Calculate the performance metrics\n",
        "rf_acc = accuracy_score(y_test, rf_pred)\n",
        "rf_recall = recall_score(y_test, rf_pred)\n",
        "rf_precision = precision_score(y_test, rf_pred)\n",
        "\n",
        "# Print the performance metrics\n",
        "print(f\"Random Forest - Accuracy: {rf_acc:.3f}\")\n",
        "print(f\"Random Forest - Recall: {rf_recall:.3f}\")\n",
        "print(f\"Random Forest - Precision: {rf_precision:.3f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, rf_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
        "plt.title('Random Forest Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Assuming that poly is the PolynomialFeatures instance fitted on the training data\n",
        "poly_feature_names = poly.get_feature_names_out()\n",
        "\n",
        "# Now create the DataFrame using the correct feature names\n",
        "feature_importances = pd.DataFrame(rf.best_estimator_.feature_importances_,\n",
        "                                   index=poly_feature_names,  # Updated to use all feature names\n",
        "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances)\n",
        "\n",
        "\n",
        "# ROC Curve\n",
        "y_pred_prob = rf.predict_proba(X_test_scaled)[:, 1]\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.plot(fpr, tpr, label='ROC Curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Random Forest ROC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Decision Boundary Analysis\n",
        "# Reduce dimensions for visualization\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "\n",
        "# Train Random Forest on the first two principal components for visualization\n",
        "rf_pca = RandomForestClassifier(n_estimators=100, max_depth=rf.best_params_['max_depth'])\n",
        "rf_pca.fit(X_train_pca, y_train)\n",
        "\n",
        "# Create a mesh grid on the PCA-reduced 2D space\n",
        "x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
        "y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                     np.linspace(y_min, y_max, 100))\n",
        "\n",
        "# Predict on the mesh grid\n",
        "Z = rf_pca.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot decision boundary\n",
        "plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, edgecolors='k')\n",
        "plt.xlabel('PCA1')\n",
        "plt.ylabel('PCA2')\n",
        "plt.title('Random Forest Decision Boundary with PCA-reduced Features')\n",
        "plt.show()\n",
        "\n",
        "################################################################################\n",
        "# Model Comparison                                                             #\n",
        "################################################################################\n",
        "\n",
        "# Section 7: Model Comparison with Visualization\n",
        "models = [ 'Decision Tree', 'Random Forest']\n",
        "acc_scores = [ tree_acc, rf_acc]  # Assuming these are correctly calculated\n",
        "recall_scores = [ tree_recall, rf_recall]\n",
        "precision_scores = [ tree_precision,  rf_precision]\n",
        "\n",
        "# Creating a DataFrame for scores\n",
        "performance_df = pd.DataFrame({\n",
        "    'Model': models,\n",
        "    'Accuracy': acc_scores,\n",
        "    'Recall': recall_scores,\n",
        "    'Precision': precision_scores\n",
        "})\n",
        "print(performance_df)\n",
        "\n",
        "# Plotting ROC Curves for all models\n",
        "plt.figure(figsize=(10, 8))\n",
        "for model in [ dt, rf]:\n",
        "    y_pred_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'{model.best_estimator_.__class__.__name__} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Generate and Display Lift Table\n",
        "\n",
        "def generate_lift_table(y_true, y_pred_prob, deciles=10):\n",
        "    # Create a DataFrame for calculations\n",
        "    data = pd.DataFrame({'prob': y_pred_prob, 'actual': y_true})\n",
        "\n",
        "    # Sort by predicted probabilities in descending order\n",
        "    data = data.sort_values(by='prob', ascending=False)\n",
        "\n",
        "    # Assign deciles\n",
        "    data['decile'] = pd.qcut(data['prob'], q=deciles, labels=np.arange(1, deciles + 1))\n",
        "\n",
        "    # Calculating necessary statistics per decile\n",
        "    lift_table = data.groupby('decile').agg(\n",
        "        obs=('prob', 'count'),\n",
        "        avg_score=('prob', 'mean'),\n",
        "        event_rate=('actual', 'mean'),\n",
        "        actual_events=('actual', 'sum')\n",
        "    )\n",
        "\n",
        "    # Calculating cumulative statistics\n",
        "    lift_table['cum_events'] = lift_table['actual_events'].cumsum()\n",
        "    lift_table['cum_non_events'] = (lift_table['obs'] - lift_table['actual_events']).cumsum()\n",
        "\n",
        "    total_events = lift_table['actual_events'].sum()\n",
        "    total_non_events = data['actual'].count() - total_events\n",
        "\n",
        "    lift_table['cum_pct_events'] = lift_table['cum_events'] / total_events\n",
        "    lift_table['cum_pct_non_events'] = lift_table['cum_non_events'] / total_non_events\n",
        "\n",
        "    # Calculating Lift and KS\n",
        "    lift_table['lift'] = lift_table['event_rate'] / (total_events / data.shape[0])\n",
        "    lift_table['KS'] = np.abs(lift_table['cum_pct_events'] - lift_table['cum_pct_non_events'])\n",
        "\n",
        "    # Resetting index for a better view\n",
        "    lift_table.reset_index(inplace=True)\n",
        "\n",
        "    return lift_table\n",
        "\n",
        "# Generate lift table for the best model (Assuming best_model and y_pred_prob have been identified)\n",
        "lift_table = generate_lift_table(y_test, y_pred_prob)\n",
        "print(lift_table)"
      ]
    }
  ]
}